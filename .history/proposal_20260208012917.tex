% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
% Include other packages here, before hyperref.
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{float}
\usepackage{textcomp}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}


\title{Automated Footwear Classification} \author{%
	\small % smaller font for the whole line
	\makebox[\textwidth][c]{%
		Baila Ly {\tt\small 4027963} \quad
		Sanjay Thambithrurai {\tt\small 4018440} \quad
		Benjamin Zitella {\tt\small 4021138} \quad
		Jia Hao To {\tt\small 40263401} \quad
		Rasel Abdul Samad {\tt\small 4020992}%
	}%
}
\begin{document}
	\maketitle
	%%%%%%%%% BODY TEXT
	\section{Problem Statement}
	\label{sec:intro}
	The intent of footwear classification is to automate identification of footwear types from images, enabling efficient visual understanding for downstream applications.
	Footwear type classification from images is an important computer vision problem for applications in e-commerce, visual search, and product categorization. However, the task is challenging due to large visual variations of the same footwear categories, and diverse imaging conditions present. 
	
	
	The objective of this project is to evaluate the performance and scalability of various convolutional neural networks (CNN) architectures for footwear images classification across datasets of different complexity. We aim for the results to provide insights into the relationship between the dataset scale and model capacity, such as its strength and limitations of various CNNs when applied to the real-world footwear classification task.
	
	\section{Dataset Selection}
	\label{sec:dataset}
	\begin{table}[H]
		\centering
		\begin{tabular}{@{}l c @{\hspace{1cm}} c c@{}}
			\toprule
			Dataset & Class & Imag/Class & Resolution\\
			\midrule
			name1 & 0 & 0 & 0\\
			name2 & 0 & 0 & 0\\
			name3 & 0 & 0 & 0\\
			\bottomrule
		\end{tabular}
		\caption{insert text}
		\label{tab:example}
	\end{table}
	
	\section{Possible Methodology}
	\label{sec:Method}
		\subsection{Pipeline}
	Our pipeline focuses on comparing from-scratch baseline models to those utilizing transfer learning
	.Three architecture will be implemented: ResNet-50[4], MobileNetV2[5], and VGG-16[6].
	All three models will be trained from scratch accross three different dataset configurations 
	listed in table \ref{tab:datasets} (Footwear 3K, Shoes Classification, and UT Zappos50K) with a total of nine models. These models will be evaluated against two
	transfer learning versions (ResNet-50 and MobileNetV2) to assess efficiency pre-trained weigths in the 
	retail imagery domain.

	\subsection{Data Processing and Training}
	Images will be resized to 224 x 224[7] and normalized using ImageNet mean and standard deviation to 
	guarantee compatibility with pre-trained weights[8]. A 70/15/15 train/validation/test split will be 
	utilized in order to prevent overfitting. Real-time augmentations such as horizontal flips, 
	\textpm 20\textdegree rotations and zooming will be implemented to handle class imbalance and further 
	mitigate overfitting. Training will be performed using the loss algorithim Adam optimizer 
	with a learning rate of $10^-4$[9] and the loss function Categorical Cross-Entropy
	loss over 50 epochs[10] . The MobileNetV2 will be will be specifically targetted during hyperparameter 
	tuning, optimizing batch size(16,32,64)[11] and dropout rates to improve performance.

	\subsection{Evaluation and Analysis}
	The model performance will be evaluated using Top-1 Accuracy, Precision, Recall, and F-1Score. 
	Transfer learning models are expected to reach above 92\% in accuraccy on the catalog-style UT Zappos50K data, 
	while scratch models may struggle with granularity of its 12 subcategories. Feature extraction will be analyzed using 
	T-SNE for dimensional reduction of latent space[12] and Grad-CAM will serve to vizualize class-discriminative regions
	in at least four of our models[13]. Failure cases will be evaluated with Confusion Matrices to provide
	scientific insights into intra-class variance a common challenge in resilient automated visual search tools[14].

% 
	
	\clearpage
	\section{Gantt Chart}
	\label{sec:chart}
	
	
	\begin{figure}[H]  % H = "here" (requires float package)
		\centering
		%%\includegraphics[width=0.8\textwidth]{image.png}  % Adjust width as needed
		\caption{Gantt Chart for Project Timeline}
		\label{fig:gantt}
	\end{figure}

	
	
	\clearpage
	\section{Bibliography}
	
	
	%%%%%%%%% REFERENCES
	{\small
		\bibliographystyle{ieee_fullname}
		\bibliography{egbib}
	}
	
\end{document}
