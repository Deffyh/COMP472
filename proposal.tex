% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{float}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}


\title{Automated Footwear Classification} \author{%
	\small % smaller font for the whole line
	\makebox[\textwidth][c]{%
		Baila Ly {\tt\small 4027963} \quad
		Sanjay Thambithrurai {\tt\small 4018440} \quad
		Benjamin Zitella {\tt\small 4021138} \quad
		Jia Hao To {\tt\small 40263401} \quad
		Rasel Abdul Samad {\tt\small 4020992}%
	}%
}
\begin{document}
	\maketitle
	%%%%%%%%% BODY TEXT
	\section{Problem Statement}
	\label{sec:intro}	
	The objective of this project is to evaluate the performance and scalability of various convolutional neural networks (CNN) architectures for footwear images classification across datasets of different complexity. We aim for the results to provide insights into the relationship between the dataset scale and model capacity, such their strengths and limitations of various CNNs when applied to the real-world footwear classification task.

	The objective of this project is to evaluate the performance and scalability of various convolutional neural networks (CNN) architectures for footwear images classification across datasets of different complexity. We aim for the results to provide insights into the relationship between the dataset scale and model capacity, such as its strength and limitations of various CNNs when applied to the real-world footwear classification task.

	\section{Dataset Selection}
	\label{sec:dataset}
	 We selected three shoe classification datasets downloadable from Kaggle with varying complexity. All use JPEG format with RGB color space.
	\begin{table}[H]
		\centering
		\small
		\begin{tabular}{@{}lcccc@{}}
			\toprule
			\textbf{Dataset} & \textbf{Cls} & \textbf{Total} & \textbf{Img/Cls} & \textbf{Res.} \\
			\midrule
			Footwear 3K \cite{footwear3k} & 3 & 3,000 & 1,000 & 136$\times$102 \\
			Shoes Classification \cite{shoesclassification} & 5 & 13,715 & 2,600-2,900 & Variable \\
			UT Zappos50K \cite{utzappos50k} & 12 & 50,025 & 1,500-2,000 & 136$\times$102 \\
			\bottomrule
		\end{tabular}
		\caption{Footwear datasets with varying class granularity.}
		\label{tab:datasets}
	\end{table}
	The pre-defined train/validation/test folder splits provided by the Shoes Classification Dataset will be used exactly as is. There are no pre-defined splits in the Footwear: Shoe vs. Sandal vs. Boot and UT Zappos50K datasets. During preprocessing, we will define stratified 70/15/15 train/validation/test divides for the Footwear dataset. Using \textit{stratified random sampling}, we will first subsample the 50,025 images for UT Zappos50K. We will extract the 12 most common functional subcategories from the metadata (e.g., running shoes, high heels, loafers, and oxfords), then randomly sample 1,500â€“2,000 images per subcategory without replacement (seed=42), and create 70/15/15 splits.
	
	\section{Possible Methodology}
	\label{sec:Method}
	\subsection{Pipeline}
	Our pipeline focuses on comparing models trained from scratch to those utilizing transfer learning
	.Three architecture will be implemented: ResNet-50[4], MobileNetV2[5], and VGG-16[6].
	All three models will be trained from scratch accross three different datasets of increasing class granularity with a total of nine models. These models will be evaluated against two
	transfer learning versions (ResNet-50 and MobileNetV2) to assess efficiency pre-trained weigths in the 
	retail imagery domain.
	
	\subsection{Data Processing and Training}
	Images will be resized to 224 x 224[7] and normalized using ImageNet mean and standard deviation to 
	guarantee compatibility with pre-trained weights[8]. A 70/15/15 train/validation/test split will be 
	utilized in order to prevent overfitting. Real-time augmentations such as horizontal flips, 
	\textpm 20\textdegree rotations and zooming will be implemented to improve generalization and reduce overfitting and further 
	mitigate overfitting. Training will be performed using the loss algorithim Adam optimizer 
	with a learning rate of $1\cdot10^{-4}$[9] and the loss function $CrossEntropyLoss$[10] 
	loss over 50 epochs. The MobileNetV2 will be will be specifically targetted during hyperparameter 
	tuning, optimizing batch size(16,32,64)[11] and dropout rates to improve performance.
	% 
	
	\clearpage
	\section{Gantt Chart}
	\label{sec:chart}
	
	
	\begin{figure}[H]  % H = "here" (requires float package)
		\centering
		%\includegraphics[width=0.8\textwidth]{image.png}  % Adjust width as needed
		\caption{Gantt Chart for Project Timeline}
		\label{fig:gantt}
	\end{figure}

	
	
	\clearpage
	\section{Bibliography}
	
	
	%%%%%%%%% REFERENCES
	{\small
		\bibliographystyle{ieee_fullname}
		\bibliography{egbib}
	}
	
\end{document}
